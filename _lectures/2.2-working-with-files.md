---
week: 2
lecture: 2
lang: python
title: Working with files
description: Python is extremely good at data processing and reading and writing to files in various formats. This lecture covers the basic of file IO in python and introduces the pathlib, CSV and JSON modules from the standard library.
---

---

## Accessing files with `open()`

Write mode, `'w'`

```python
file = open('shopping.txt', 'w')
file.write("apples")
file.write("bananas")
file.write("cherries")
file.close()
```

Read mode, `'r'`

```python
file = open('shopping.txt', 'r')
print(file.read())
file.close()
```
{: .small-margin}
```plaintext
applesbananascherries
```
{: .small-margin}

---

## Context manager

A context manager is an object that defines the context of a `with` statement.
The built-in function `open()` is the most commonly used context manager in python.
It manages both opening and closing a file so the context of the code block includes an open file handle.

```python
with open('shopping.txt', 'w') as file:
    file.write("apples")
    file.write("bananas")
    file.write("cherries")
```

This code will always automatically close your files and should **always** be used when accessing files.

```python
with open('shopping.txt', 'r') as file:
    print(file.read())
```
{: .small-margin}
```plaintext
applesbananascherries
```
{: .small-margin}

---

## What is this file object?

The `open()` function returns different object types, depending on the mode.

```python
for mode in ['r', 'w', 'rb', 'wb']:
    with open('shopping.txt', mode) as f:
        print(f"{mode}: {f}")
```
{: .small-margin}
```plaintext
r: <_io.TextIOWrapper name='shopping.txt' mode='r' encoding='UTF-8'>
w: <_io.TextIOWrapper name='shopping.txt' mode='w' encoding='UTF-8'>
rb: <_io.BufferedReader name='shopping.txt'>
wb: <_io.BufferedWriter name='shopping.txt'>
```
{: .small-margin}

Notice that text file objects are the default and that they default to `utf-8` encoding, 
In most cases the default read (`r`) and write (`w`) modes are all you will ever need.

However, if you are working with files with binary formats, then it is possible.

> *Markup languages* such as HTML are all about human-readability

---

## Creating line-oriented files

Notice that the result we got when we wrote data into our `'shopping.txt'` file was all in one line.

```plaintext
applesbananascherries
```

We can add literal newline characters into our files to write line-oriented data.

```python
shopping = ['apples', 'bananas', 'cherries']
with open('shopping.txt', 'w') as file:
    for item in shopping:
        file.write(f"{item}\n")
```

This produces a result which is clearly easier to parse.

```plaintext
apples
bananas
cherries
```

---

## Using `print()` with files

The `print()` function takes an optional `file` argument.

```python
shopping = ['apples', 'bananas', 'cherries']
with open('shopping.txt', 'w') as file:
    for item in shopping:
        print(item, file=file)
```

This produce an equivalent result. 

```plaintext
apples
bananas
cherries
```

This is because `print()` takes a `end` argument which defaults to a newline character, `\n`.

---

## Parsing line-oriented data

With a line-oriented file, we can extract lines, one at a time using the `readline()` method.
Each call will read data from the file up to and including the next `'\n'` character.
If we print the output, then we end up adding an extra newline character.

```python
with open('shopping.txt', 'r') as file:
    apples = file.readline()
print(apples) # 'apples\n'
```

Calling `readlines()` will generate a list of all the line-oriented data within a file, with the `'\n'` characters intact.

```python
with open('shopping.txt', 'r') as file:
    data = file.readlines()
print(data[1]) # 'bananas\n'
```


---

## Files are iterable

Files are iterable, so we can convert them to a list by passing a file object into the `list` constructor.

```python
with open('shopping.txt', 'r') as file:
    shopping = list(file)
print(shopping)
```
{: .small-margin}
```plaintext
['apples\n', 'bananas\n', 'cherries\n']
```
{: .small-margin}

Looping is also possible. 
Which will keep the memory footprint lower.

```python
with open('shopping.txt', 'r') as file:
    for line in file:
        print(line)
```

Again, in both cases the newline characters are kept.


---

## Parsing data in other ways

To remove the newline characters we can call `str.split('\n')` on the entire file contents.

```python
with open('shopping.txt', 'r') as file:
    shopping = file.read().split('\n'):
print(shopping)
```
{: .small-margin}
```plaintext
['apples', 'bananas', 'cherries']
```
{: .small-margin}

However, if our file is empty this will give a single item list containing one empty string.
This is why the string method `splitlines()` exists.

```python
with open('shopping.txt', 'r') as file:
    shopping = file.read().splitlines()
print(shopping)
```
{: .small-margin}
```plaintext
['apples', 'bananas', 'cherries']
```
{: .small-margin}

---

## Using `pathlib`

Many complex issues arise when managing files and folders for a cross-platform application.
An excellent tool in the python standard library is the `pathlib` module.
The core `pathlib` tool is the `Path` class which provides an object-oriented interface representing locations in the filesystem. 

```python
from pathlib import Path

my_path = Path('folder1', 'folder2', 'filename.txt')
print(repr(my_path))
print(repr(my_path.absolute()))
```
{: .small-margin}
```plaintext
PosixPath('folder1/folder2/filename.txt')
PosixPath('/home/graeme/Teaching/GAMR1520/folder1/folder2/filename.txt')
```
{: .small-margin}

Notice we are using `repr()` above to print the *string representation* of the path object.

> Note that the result will be platform dependent and the file may or may not exist at this point.

---


## `mkdir()` and `touch()`

We can see that the file doesn't exist.

```python
my_path = Path('folder1', 'folder2', 'filename.txt')
print(my_path.exists())
```
{: .small-margin}
```plaintext
False
```
{: .small-margin}

We can create the containing folders and the file.

```python
my_path.mkdir(parents=True)
my_path.touch()
print(my_path.exists)
```
{: .small-margin}
```plaintext
True
```
{: .small-margin}

---

## `iter_dir()`, `is_dir()` and `is_file()`

We can iterate over the file system.

```python
from pathlib import Path

here = Path('.')
for p in here.iterdir():
    if p.is_dir():
        print(str(p).ljust(20), "(folder)", sep="\t")
    if p.is_file():
        print(str(p).ljust(20), "(file)", sep="\t")
```
{: .small-margin}
```plaintext
shopping.txt        (file)
list.txt            (file)
string.txt          (file)
folder1             (folder)
my_experiments      (folder)
script.py           (file)
```
{: .small-margin}


---

## Joining paths

The `Path.joinpath()` method can be used to create new `Path` objects.

```python
root = Path('folder')
my_path = root.joinpath('filename.txt')
```

Alternatively, we can use the slash operator (`/`) to join paths.
This is equivalent to the above.

```python
root = Path('folder')
my_path = root / 'filename.txt'
```

> As we shall see, this makes manipulating files and generating directory structures very simple.

---

## `Path.open()`

Conveniently, the `Path` object includes an `open` method which calls the built-in `open` function for us.
So we can create and populate multiple files with a simplified loop.

```python
root = Path('folder')
root.mkdir()

all_lists = {
    'fruit': ['apples', 'bananas', 'cherries'],
    'colours': ['aquamarine', 'blue', 'cyan'],
    'animals': ['armadillo', 'baboon', 'cat']
}

for title, my_list in all_lists.items():
    my_path = root / f'{title}.txt'
    with my_path.open('w') as my_file:
        for item in my_list:
            print(item, file=my_file)
```
{: .small-margin}


---

## What if I have more complex data?

animals.py
{: .small-margin}

```python
animals = [{'name': 'Anteater', 'description': 'Eats ants'},
           {'name': 'Bear', 'description': 'Grizzly'},
           {'name': 'Chimp', 'description': 'Chump'},
           {'name': 'Dog', 'description': 'Friend'}]
```
{: .small-margin}

animals.csv
{: .small-margin}

```plaintext
name,description
Anteater,Eats ants
Bear,Grizzly
Chimp,Chump
Dog,Friend
```
{: .small-margin}

animals.json
{: .small-margin}

```json
[{"name": "Anteater", "description": "Eats ants"}, {"name": "Bear", "description": "Grizzly"}, {"name": "Chimp", "description": "Chump"}, {"name": "Dog", "description": "Friend"}]
```
{: .small-margin}

---

## Write as CSV

The `csv` module takes some getting used to, but is really very simple.

```python
from pathlib import Path
from csv import DictWriter

animals = [{'name': 'Anteater', 'description': 'Eats ants'},
           {'name': 'Bear', 'description': 'Grizzly'},
           {'name': 'Chimp', 'description': 'Chump'},
           {'name': 'Dog', 'description': 'Friend'}]

path = Path('animals.csv')

with path.open('w') as file:
    writer = DictWriter(file, fieldnames=['name', 'description'])
    writer.writeheader()
    writer.writerows(animals)
```

---

## Write as JSON

import json

```python
from pathlib import Path
import json

animals = [{'name': 'Anteater', 'description': 'Eats ants'},
           {'name': 'Bear', 'description': 'Grizzly'},
           {'name': 'Chimp', 'description': 'Chump'},
           {'name': 'Dog', 'description': 'Friend'}]

path = Path('animals.json')

with path.open('w') as file:
    json.dump(animals, file, indent=2)
```

---

## JSON to CSV

Say you need to read from a JSON file and write into a CSV file.
This requires `json.load()` and a `csv.DictWriter` object.
One `with` clause can open both files.

```python
from pathlib import Path 
from csv import DictReader
import json

inpath = Path('animals.json')
outpath = Path('animals_from_json.csv')

with inpath.open('r') as infile, outpath.open('w') as outfile:
    data = json.load(infile)
    writer = DictWriter(outfile, fieldnames=['name', 'description'])
    writer.writeheader()
    writer.writerows(animals)
```

> We need to write the CSV header row before we write all the data.

---

## CSV to JSON

Converting in the other direction requires a `csv.DictReader` object and `json.dump()`.

> Notice the `csv.DictReader` object will use the header row to determine the field names.
Also, because it's iterable, we can just pass it into `list()` to load all the data.


```python
from pathlib import Path 
from csv import DictReader
import json

inpath = Path('animals.csv')
outpath = Path('animals_from_csv.json')

with inpath.open('r') as infile, outpath.open('w') as outfile:
    animals = list(DictReader(infile))
    json.dump(animals, outfile, indent=2)
```
